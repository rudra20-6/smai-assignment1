{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy scikit-learn pandas\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights: [ 0.00086493  0.31463956  0.00081246 -0.0032014  -0.00750073 -0.0030633\n",
      "  0.00436927 -0.00299162]\n",
      "Learned Bias: 0.055626626291274996\n",
      "Test MSE: 0.4972310045989274\n",
      "Test R^2 Score: 0.42492165447851604\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def stochastic_gradient_descent_lasso(X, y, lr=0.01, epochs=1000, lambda_=0.1):\n",
    "    \"\"\"\n",
    "    Perform stochastic gradient descent with Lasso (L1) regularization.\n",
    "\n",
    "    Parameters:\n",
    "    X : numpy.ndarray\n",
    "        Feature matrix (n_samples, n_features)\n",
    "    y : numpy.ndarray\n",
    "        Target values (n_samples,)\n",
    "    lr : float, optional\n",
    "        Learning rate (default is 0.01)\n",
    "    epochs : int, optional\n",
    "        Number of iterations (default is 1000)\n",
    "    lambda_ : float, optional\n",
    "        Regularization strength (default is 0.1)\n",
    "\n",
    "    Returns:\n",
    "    w : numpy.ndarray\n",
    "        Learned weight vector\n",
    "    b : float\n",
    "        Learned bias term\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    w = np.zeros(n_features)  # Initialize weights\n",
    "    b = 0  # Initialize bias\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(n_samples):\n",
    "            idx = np.random.randint(0, n_samples)  # Select random sample\n",
    "            X_i, y_i = X[idx], y[idx]\n",
    "            \n",
    "            y_pred = np.dot(X_i, w) + b\n",
    "            error = y_pred - y_i\n",
    "            \n",
    "            # Compute gradients\n",
    "            dw = (X_i * error) + (lambda_ * np.sign(w))  # L1 regularization term\n",
    "            db = error\n",
    "            \n",
    "            # Update parameters\n",
    "            w -= lr * dw\n",
    "            b -= lr * db\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "train_data = pd.read_csv(\"./srcfiles/train_standardized.csv\")\n",
    "val_data = pd.read_csv(\"./srcfiles/validation_standardized.csv\")\n",
    "\n",
    "# Split features and target\n",
    "X_train = train_data.iloc[:, :-1].values\n",
    "y_train = train_data.iloc[:, -1].values\n",
    "X_val = val_data.iloc[:, :-1].values\n",
    "y_val = val_data.iloc[:, -1].values\n",
    "\n",
    "w, b = stochastic_gradient_descent_lasso(X_train, y_train, lr=0.01, epochs=10, lambda_=0.5)\n",
    "print(\"Learned Weights:\", w)\n",
    "print(\"Learned Bias:\", b)\n",
    "\n",
    "# Load test set from CSV\n",
    "test_data = pd.read_csv(\"./srcfiles/test_standardized.csv\")\n",
    "X_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data.iloc[:, -1].values\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_test = np.dot(X_test, w) + b\n",
    "\n",
    "# Calculate MSE and R^2 Score\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test R^2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m mse_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lambda_ \u001b[38;5;129;01min\u001b[39;00m lambdas:\n\u001b[1;32m----> 5\u001b[0m     w, b \u001b[38;5;241m=\u001b[39m \u001b[43mstochastic_gradient_descent_lasso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     y_pred_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_test, w) \u001b[38;5;241m+\u001b[39m b\n\u001b[0;32m      7\u001b[0m     mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred_test)\n",
      "Cell \u001b[1;32mIn[17], line 32\u001b[0m, in \u001b[0;36mstochastic_gradient_descent_lasso\u001b[1;34m(X, y, lr, epochs, lambda_)\u001b[0m\n\u001b[0;32m     29\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, n_samples)  \u001b[38;5;66;03m# Select random sample\u001b[39;00m\n\u001b[0;32m     30\u001b[0m X_i, y_i \u001b[38;5;241m=\u001b[39m X[idx], y[idx]\n\u001b[1;32m---> 32\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b\n\u001b[0;32m     33\u001b[0m error \u001b[38;5;241m=\u001b[39m y_pred \u001b[38;5;241m-\u001b[39m y_i\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambdas = np.linspace(0, 1, 10)\n",
    "mse_values = []\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    w, b = stochastic_gradient_descent_lasso(X_train, y_train, lr=0.01, epochs=10, lambda_=lambda_)\n",
    "    y_pred_test = np.dot(X_test, w) + b\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "# Plot MSE vs Lambda\n",
    "plt.plot(lambdas, mse_values, marker='o')\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.title(\"MSE vs Lambda (Lasso)\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
