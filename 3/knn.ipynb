{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\choud\\onedrive\\desktop\\newcollegedocs\\2-2\\smai\\a1\\smai-assignment1\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using euclidean distance:\n",
      "preds: tensor([6, 8, 8,  ..., 5, 0, 7])\n",
      "test_labels: tensor([3, 8, 8,  ..., 5, 1, 7])\n",
      "Accuracy for k=1: 0.9048\n",
      "preds: tensor([3, 8, 8,  ..., 5, 0, 7])\n",
      "test_labels: tensor([3, 8, 8,  ..., 5, 1, 7])\n",
      "Accuracy for k=5: 0.9182\n",
      "preds: tensor([3, 8, 8,  ..., 5, 0, 7])\n",
      "test_labels: tensor([3, 8, 8,  ..., 5, 1, 7])\n",
      "Accuracy for k=10: 0.9194\n",
      "\n",
      "Using cosine distance:\n",
      "preds: tensor([6, 8, 8,  ..., 5, 0, 7])\n",
      "test_labels: tensor([3, 8, 8,  ..., 5, 1, 7])\n",
      "Accuracy for k=1: 0.9048\n",
      "preds: tensor([3, 8, 8,  ..., 5, 0, 7])\n",
      "test_labels: tensor([3, 8, 8,  ..., 5, 1, 7])\n",
      "Accuracy for k=5: 0.9182\n",
      "preds: tensor([3, 8, 8,  ..., 5, 0, 7])\n",
      "test_labels: tensor([3, 8, 8,  ..., 5, 1, 7])\n",
      "Accuracy for k=10: 0.9194\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "def load_data_1():\n",
    "    train_embeddings = torch.load(\"./srcFiles/train_embeddings.pth\")\n",
    "    test_embeddings = torch.load(\"./srcFiles/test_embeddings.pth\")\n",
    "    train_labels = torch.load(\"./srcFiles/train_labels.pth\")\n",
    "    test_labels = torch.load(\"./srcFiles/test_labels.pth\")\n",
    "    return train_embeddings, test_embeddings, train_labels, test_labels\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    return torch.cdist(a, b, p=2)\n",
    "\n",
    "def cosine_distance(a, b):\n",
    "    a_norm = a / a.norm(dim=1, keepdim=True)\n",
    "    b_norm = b / b.norm(dim=1, keepdim=True)\n",
    "    return 1 - torch.mm(a_norm, b_norm.T)\n",
    "\n",
    "def knn(train_emb, test_emb, train_labels, k, metric=\"euclidean\"):\n",
    "    distances = euclidean_distance(test_emb, train_emb) if metric == \"euclidean\" else cosine_distance(test_emb, train_emb)\n",
    "    knn_indices = distances.topk(k, largest=False).indices\n",
    "    knn_labels = train_labels[knn_indices]\n",
    "    \n",
    "    predictions = torch.mode(knn_labels, dim=1).values\n",
    "    return predictions\n",
    "\n",
    "def compute_accuracy(predictions, true_labels):\n",
    "    return (predictions == true_labels).float().mean().item()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_emb, test_emb, train_labels, test_labels = load_data_1()\n",
    "    \n",
    "    k_values = [1, 5, 10]\n",
    "    metrics = [\"euclidean\", \"cosine\"]\n",
    "    \n",
    "    for metric in metrics:\n",
    "        print(f\"\\nUsing {metric} distance:\")\n",
    "        for k in k_values:\n",
    "            preds = knn(train_emb, test_emb, train_labels, k, metric)\n",
    "            print(f'preds: {preds}')\n",
    "            print(f'test_labels: {test_labels}')\n",
    "            acc = compute_accuracy(preds, test_labels)\n",
    "            print(f\"Accuracy for k={k}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using euclidean distance:\n",
      "Accuracy for k=1: 0.8781\n",
      "\n",
      "Using cosine distance:\n",
      "Accuracy for k=1: 0.8781\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def load_data_2():\n",
    "    device = torch.device('cpu')\n",
    "    text_embeddings = torch.load(\"./srcFiles/text_embedding.pth\", map_location=device)\n",
    "    test_embeddings = torch.load(\"./srcFiles/test_embeddings.pth\", map_location=device)\n",
    "    test_labels = torch.load(\"./srcFiles/test_labels.pth\", map_location=device)\n",
    "    return text_embeddings, test_embeddings, test_labels\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    return torch.cdist(a, b, p=2)\n",
    "\n",
    "def cosine_distance(a, b):\n",
    "    a_norm = a / a.norm(dim=1, keepdim=True)\n",
    "    b_norm = b / b.norm(dim=1, keepdim=True)\n",
    "    return 1 - torch.mm(a_norm, b_norm.T)\n",
    "\n",
    "def knn_text(text_emb, test_emb, k=1, metric=\"euclidean\"):\n",
    "    distances = euclidean_distance(test_emb, text_emb) if metric == \"euclidean\" else cosine_distance(test_emb, text_emb)\n",
    "    closest_indices = distances.argmin(dim=1)\n",
    "    return closest_indices\n",
    "\n",
    "def compute_accuracy(predictions, true_labels):\n",
    "    return (predictions == true_labels).float().mean().item()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text_emb, test_emb, test_labels = load_data_2()\n",
    "    \n",
    "    metrics = [\"euclidean\", \"cosine\"]\n",
    "    \n",
    "    for metric in metrics:\n",
    "        print(f\"\\nUsing {metric} distance:\")\n",
    "        preds = knn_text(text_emb, test_emb, metric=metric)\n",
    "        acc = compute_accuracy(preds, test_labels)\n",
    "        print(f\"Accuracy for k=1: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_reciprocal_rank(knn_labels, actual_labels):\n",
    "\n",
    "#     ranks_list = []\n",
    "    \n",
    "#     for i in range(len(actual_labels)):\n",
    "#         matching_indices = (knn_labels[i] == actual_labels[i]).nonzero(as_tuple=True)[0]\n",
    "#         print(f\"matching_indices: {matching_indices}\")\n",
    "#         print(f\"actual_labels[i]: {actual_labels[i]}\")\n",
    "#         first_occurrence = matching_indices.min().item() + 1\n",
    "#         ranks_list.append(first_occurrence)\n",
    "    \n",
    "#     ranks = torch.tensor(ranks_list, dtype=torch.float)\n",
    "    \n",
    "#     return (1 / ranks).mean().item()\n",
    "\n",
    "def mean_reciprocal_rank(knn_labels, actual_labels):\n",
    "    #To calculate the ranks without using for loop, we get a boolean array of the matches and then multiply it with the indices starting from 1\n",
    "    #This way in the indices array we get the indices on which we have match\n",
    "    #we extract the first occurrence of the match for each query and then filter out the invalid cases\n",
    "    \n",
    "    \n",
    "    matches = knn_labels == actual_labels.view(-1, 1)\n",
    "    indices = matches.float() * (torch.arange(1, knn_labels.shape[1] + 1, device=knn_labels.device))  # Create 1-based indices\n",
    "    # print(f\"indices: {indices}\")\n",
    "    indices = torch.where(matches, indices, torch.tensor(float('inf'), device=knn_labels.device)) # replacing 0s with inf\n",
    "\n",
    "    ranks = indices.min(dim=1)[0]  # max() ensures the first nonzero index is selected\n",
    "    \n",
    "    # print(f\"ranks: {ranks}\")\n",
    "    \n",
    "\n",
    "    ranks[ranks == 0] = float('inf')  # If no match, reciprocal rank = 0\n",
    "\n",
    "    # if valid_ranks.numel() == 0:  \n",
    "    #     return 0.0\n",
    "\n",
    "    return (1.0 / ranks).mean().item()\n",
    "\n",
    "\n",
    "def precision_at_k(knn_labels, actual_labels, k=100):\n",
    "\n",
    "    correct_predictions = (knn_labels[:, :k] == actual_labels.view(-1, 1)).sum(dim=1).float()\n",
    "    precision = (correct_predictions / k).mean().item()\n",
    "    return precision\n",
    "\n",
    "\n",
    "def hit_rate(knn_labels, actual_labels, k=100):\n",
    "    hits = (knn_labels[:, :k] == actual_labels.view(-1, 1)).any(dim=1).float()\n",
    "    return hits.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Cosine distance:\n",
      "MRR: 1.0000\n",
      "Precision@100: 0.9740\n",
      "Hit rate@100: 1.0000\n",
      "\n",
      "Using Euclidean distance:\n",
      "MRR: 1.0000\n",
      "Precision@100: 0.9740\n",
      "Hit rate@100: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def knn_TtoIRetreival(text_emb, train_emb, train_labels, k = 100, metric = \"euclidean\"):\n",
    "    distances = euclidean_distance(text_emb, train_emb) if metric == \"euclidean\" else cosine_distance(text_emb, train_emb)\n",
    "    knn_indices = distances.topk(k, largest=False).indices\n",
    "    knn_labels = train_labels[knn_indices]\n",
    "        \n",
    "    mrr = mean_reciprocal_rank(knn_labels, torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "    precision = precision_at_k(knn_labels, torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "    hit_rate_ = hit_rate(knn_labels, torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "    \n",
    "    print(f\"MRR: {mrr:.4f}\")\n",
    "    print(f\"Precision@{k}: {precision:.4f}\")\n",
    "    print(f\"Hit rate@{k}: {hit_rate_:.4f}\")\n",
    "    return knn_indices\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text_emb, test_emb, test_labels = load_data_2()\n",
    "    train_emb, _, train_labels, _ = load_data_1()\n",
    "    \n",
    "    print(\"\\nUsing Cosine distance:\")\n",
    "    knn_indices = knn_TtoIRetreival(text_emb, train_emb, train_labels, k=100, metric=\"cosine\")\n",
    "    print(f\"\\nUsing Euclidean distance:\")\n",
    "    knn_indices = knn_TtoIRetreival(text_emb, train_emb, train_labels, k=100, metric=\"euclidean\")\n",
    "    # print(f\"knn_indices: {knn_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Cosine distance:\n",
      "MRR: 0.9348\n",
      "Precision@100: 0.8411\n",
      "Hit rate@100: 0.9996\n",
      "\n",
      "Using Euclidean distance:\n",
      "MRR: 0.9348\n",
      "Precision@100: 0.8411\n",
      "Hit rate@100: 0.9996\n"
     ]
    }
   ],
   "source": [
    "def knn_ItoIRetreival(test_emb, train_emb, train_labels, test_labels, k = 100, metric = \"euclidean\"):\n",
    "    distances = euclidean_distance(test_emb, train_emb) if metric == \"euclidean\" else cosine_distance(test_emb, train_emb)\n",
    "    knn_indices = distances.topk(k, largest=False).indices\n",
    "    knn_labels = train_labels[knn_indices]\n",
    "    \n",
    "    # print(f\"knn_labels: {knn_labels.shape}\\n{knn_labels}\")\n",
    "    # print(f\"test_labels:{test_labels.shape} \\n{test_labels}\")\n",
    "    \n",
    "    mrr = mean_reciprocal_rank(knn_labels, test_labels)\n",
    "    precision = precision_at_k(knn_labels, test_labels)\n",
    "    hit_rate_ = hit_rate(knn_labels, test_labels)\n",
    "    \n",
    "    print(f\"MRR: {mrr:.4f}\")\n",
    "    print(f\"Precision@{k}: {precision:.4f}\")\n",
    "    print(f\"Hit rate@{k}: {hit_rate_:.4f}\")\n",
    "    return knn_indices\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text_emb, test_emb, test_labels = load_data_2()\n",
    "    train_emb, _, train_labels, _ = load_data_1()\n",
    "    \n",
    "    print(\"\\nUsing Cosine distance:\")\n",
    "    knn_indicess = knn_ItoIRetreival(test_emb, train_emb, train_labels, test_labels, k=100, metric=\"cosine\")\n",
    "    print(f\"\\nUsing Euclidean distance:\")\n",
    "    knn_indicesss = knn_ItoIRetreival(test_emb, train_emb, train_labels, test_labels, k=100, metric=\"euclidean\")\n",
    "    # print(f\"knn_indices: {knn_indices}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
